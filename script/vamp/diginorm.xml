<tool id="diginorm" name="Reduce the coverage">
	<command interpreter="python"> diginorm.py -i $input -C $cutoff -N $hashnum -x $hashsize $pairflag </command>
	<inputs>
		<param type="data" format="fasta,fastq" name="input" label="File to diginorm" help="shotgun seuquecing data of fasta or fastq format"/>
		<param type="select" name="pairflag" label="sequence type">
			<option value="-p">paired end</option>
			<option value="">single end</option>
		</param>

		<param type="integer" name="cutoff" size="15" value="10" label="Coverage cutoff"/>
		<param type="integer" name="hashnum" size="15" value="4" label="Number of hash table to use" help="Caution: Only change when experiencing error"/>
		<param type="text" name="hashsize" size="25" value="1e8" label="Lower bound on hashsize to use" help="Caution: Only change when experiencing error" />
	</inputs>
	<outputs>
		<data name="seoutput" format="fasta" label="${tool.name} on ${on_string}.se" from_work_dir="diginorm_out.se.fasta"/>
		<data name="peoutput" format="fasta" label="${tool.name} on ${on_string}.pe" from_work_dir="diginorm_out.pe.fasta"/>
	</outputs>

	<help>

**Diginorm Tools**

Digital Normalization uses a single-pass computational algorithm that systematizes coverage in shotgun sequencing data set, thus to decreasing sampling variation and discarding redundant data. Digital normalization substantially reduces the size of shotgun data sets and decreases the memory and time requirements for de novo sequence assembly, all without significantly impacting content of the generated contigs.

Since this process will slightly only one end of some reads, two files will be generated after digital normalization, containing paired-end reads and single-end reads, nameing \*.pe.fasta and \*.se.fasta. Statistics shows about 90% of the reads in the output remain paired.

	</help>
</tool>
